from flask import Flask, request
import os

app = Flask(__name__)

@app.route('/restart', methods=['GET'])
def restart():
    file_path = '/path/to/sidecar/volume/liveness-probe-file'
    with open(file_path, 'w') as f:
        f.write('restart')
    return "File created to trigger restart", 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)
--------------------------


apiVersion: apps/v1
kind: Deployment
metadata:
  name: sidecar
spec:
  replicas: 5
  selector:
    matchLabels:
      app: sidecar
  template:
    metadata:
      labels:
        app: sidecar
    spec:
      containers:
      - name: sidecar-container
        image: your-sidecar-image
        volumeMounts:
        - mountPath: /path/to/sidecar/volume
          name: sidecar-volume
        livenessProbe:
          exec:
            command:
            - cat
            - /path/to/sidecar/volume/liveness-probe-file
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: sidecar-volume
        emptyDir: {}

----------------------------
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sidecar
spec:
  replicas: 5
  selector:
    matchLabels:
      app: sidecar
  template:
    metadata:
      labels:
        app: sidecar
    spec:
      containers:
      - name: sidecar-container
        image: your-sidecar-image
        volumeMounts:
        - mountPath: /path/to/sidecar/volume
          name: sidecar-volume
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - >
              if [ -f /path/to/sidecar/volume/liveness-probe-file ]; then
                exit 1;
              else
                exit 0;
              fi
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: sidecar-volume
        emptyDir: {}

---------------------------------

from flask import Flask, request
import os

app = Flask(__name__)

@app.route('/restart', methods=['GET'])
def restart():
    file_path = '/path/to/sidecar/volume/liveness-probe-file'
    try:
        # Create the directory if it does not exist
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        # Create the file
        with open(file_path, 'w') as f:
            f.write('restart')
        return "File created to trigger restart", 200
    except Exception as e:
        return f"Failed to create file: {e}", 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)

--------------------

from flask import Flask, request
import os
import logging

# Configure logging
logging.basicConfig(level=logging.DEBUG)

app = Flask(__name__)

@app.route('/restart', methods=['GET'])
def restart():
    file_path = '/path/to/sidecar/volume/liveness-probe-file'
    try:
        # Log the file path
        app.logger.debug(f"Attempting to create directory and file at: {file_path}")
        
        # Create the directory if it does not exist
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        # Create the file
        with open(file_path, 'w') as f:
            f.write('restart')
        
        # Log success
        app.logger.debug(f"File created at: {file_path}")
        return "File created to trigger restart", 200
    except Exception as e:
        # Log the exception
        app.logger.error(f"Failed to create file: {e}")
        return f"Failed to create file: {e}", 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)

###############
from flask import Flask, request
import os
import logging

# Configure logging
logging.basicConfig(level=logging.DEBUG)

app = Flask(__name__)

@app.route('/restart', methods=['GET'])
def restart():
    file_path = '/path/to/sidecar/volume/liveness-probe-file'
    try:
        # Log the file path
        app.logger.debug(f"Attempting to write to file at: {file_path}")
        
        # Create the directory if it does not exist
        os.makedirs(os.path.dirname(file_path), exist_ok=True)
        
        # Write 'restart' to the file
        with open(file_path, 'w') as f:
            f.write('restart')
        
        # Log success
        app.logger.debug(f"Written 'restart' to file at: {file_path}")
        return "File updated to trigger restart", 200
    except Exception as e:
        # Log the exception
        app.logger.error(f"Failed to update file: {e}")
        return f"Failed to update file: {e}", 500

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)

#######################
apiVersion: apps/v1
kind: Deployment
metadata:
  name: sidecar
spec:
  replicas: 5
  selector:
    matchLabels:
      app: sidecar
  template:
    metadata:
      labels:
        app: sidecar
    spec:
      containers:
      - name: sidecar-container
        image: your-sidecar-image
        volumeMounts:
        - mountPath: /path/to/sidecar/volume
          name: sidecar-volume
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - >
              if grep -q "restart" /path/to/sidecar/volume/liveness-probe-file; then
                exit 1;
              else
                exit 0;
              fi
          initialDelaySeconds: 10
          periodSeconds: 5
      volumes:
      - name: sidecar-volume
        emptyDir: {}

///////////////////.......::::

from flask import Flask
import os

app = Flask(__name__)

@app.route('/restart', methods=['GET'])
def restart():
    file_path = '/mnt/data/test-file.txt'
    if not os.path.exists(file_path):
        return f'File {file_path} does not exist.', 404
    
    with open(file_path, 'a') as f:
        f.write('This is a test file created by hitting the /restart endpoint.\n')
    
    return f'Message written to {file_path} successfully.', 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=8080)


--------------
**Summary:**  
As per the design, we conducted a POC to identify the impediments in implementing a resource monitor to restart failed sidecars using a liveness probe.

**Requirements:**
1. Expose an endpoint in the sidecar that can be called by the resource monitor to restart the sidecar via the liveness probe:
   - The endpoint should be capable of returning a 500 response to the liveness probe health check.
   - The endpoint should be able to create a file in the sidecar volume that will be monitored by the liveness probe to trigger a pod restart.

**Observations:**
- This approach works fine for a single replica of the sidecar pod.
- For multiple replicas, the request from the resource monitor is accepted or routed to one of the sidecar replicas, causing only that sidecar to restart.

**Next Steps:**
We have additional options to explore:
- Using a headless service to broadcast a message to all sidecar replicas to restart.
- Utilizing OpenShift admin controls to manage this scenario.

______________________________________________________________________________________________

import socket
import requests
from flask import Flask, request

app = Flask(__name__)

@app.route('/broadcast', methods=['POST'])
def broadcast():
    service_name = "my-headless-service.mynamespace.svc.cluster.local"
    port = 5000
    endpoint = "/test"
    
    pod_ips = socket.gethostbyname_ex(service_name)[2]
    
    data = request.get_json()
    results = []
    
    for ip in pod_ips:
        url = f"http://{ip}:{port}{endpoint}"
        response = requests.post(url, json=data)
        results.append(f"Response from {ip}: {response.status_code}")

    # Self-call to /test endpoint
    url = f"http://localhost:{port}{endpoint}"
    response = requests.post(url, json=data)
    results.append(f"Response from self: {response.status_code}")
    
    return "Broadcast complete. Results: " + ", ".join(results), 200

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=6000)


********************************************************************************

import redis
from flask import Flask, request, jsonify
from apscheduler.schedulers.background import BackgroundScheduler
import requests
import time

app = Flask(__name__)
scheduler = BackgroundScheduler()
redis_client = redis.StrictRedis(host='localhost', port=6379, db=0)

def check_service(service_type, service_host, service_port, sidecar_url, job_id):
    try:
        # Check the status of the Redis service
        if redis_client.ping():
            print(f"{service_type} service is back online at {service_host}:{service_port}")
            redis_client.set(job_id, 'inactive')
            scheduler.remove_job(job_id)
        else:
            print(f"{service_type} service is still down at {service_host}:{service_port}")
    except Exception as e:
        print(f"Error checking {service_type} service at {service_host}:{service_port}: {e}")

@app.route('/start-monitoring', methods=['POST'])
def start_monitoring():
    payload = request.get_json()
    service_type = payload['service_type']
    service_host = payload['service_host']
    service_port = payload['service_port']
    sidecar_url = payload['sidecar_url']
    deployment_id = payload['deployment_id']  # Assume this is provided in the payload
    job_id = f'{deployment_id}_{service_type}_monitor'

    # Check if the service is already being monitored
    if redis_client.get(job_id) == b'active':
        print(f"Monitoring job for {service_type} in deployment {deployment_id} is already running")
        return jsonify(message="Monitoring job is already running"), 409

    # Set the monitoring status in Redis
    redis_client.set(job_id, 'active')

    # Schedule the monitoring job
    scheduler.add_job(
        check_service, 'interval', seconds=5, id=job_id,
        args=[service_type, service_host, service_port, sidecar_url, job_id]
    )

    print(f"Started monitoring {service_type} for deployment {deployment_id}")
    return jsonify(message="Monitoring started"), 200

@app.route('/stop-monitoring', methods=['POST'])
def stop_monitoring():
    payload = request.get_json()
    service_type = payload['service_type']
    deployment_id = payload['deployment_id']
    job_id = f'{deployment_id}_{service_type}_monitor'

    # Set the monitoring status to inactive
    redis_client.set(job_id, 'inactive')
    scheduler.remove_job(job_id)
    print(f"Stopped monitoring {service_type} for deployment {deployment_id}")
    return jsonify(message="Monitoring stopped"), 200

if __name__ == "__main__":
    scheduler.start()
    app.run(host='0.0.0.0', port=5000)
--------------------------------------------------------------------------------------------

import redis
from flask import Flask, request, jsonify
from apscheduler.schedulers.background import BackgroundScheduler
import requests
import time

app = Flask(__name__)
scheduler = BackgroundScheduler()

# Redis instance for state management
state_redis_client = redis.StrictRedis(host='localhost', port=6379, db=0)
# Redis instance for monitoring
monitoring_redis_client = redis.StrictRedis(host='monitoring_redis_host', port=6379, db=0)

def check_service(service_type, service_host, service_port, sidecar_url, job_id):
    try:
        # Check the status of the monitoring Redis service
        if monitoring_redis_client.ping():
            print(f"{service_type} service is back online at {service_host}:{service_port}")
            state_redis_client.set(job_id, 'inactive')
            scheduler.remove_job(job_id)
        else:
            print(f"{service_type} service is still down at {service_host}:{service_port}")
    except Exception as e:
        print(f"Error checking {service_type} service at {service_host}:{service_port}: {e}")

@app.route('/start-monitoring', methods=['POST'])
def start_monitoring():
    payload = request.get_json()
    service_type = payload['service_type']
    service_host = payload['service_host']
    service_port = payload['service_port']
    sidecar_url = payload['sidecar_url']
    deployment_id = payload['deployment_id']  # Assume this is provided in the payload
    job_id = f'{deployment_id}_{service_type}_monitor'

    # Check if the service is already being monitored
    if state_redis_client.get(job_id) == b'active':
        print(f"Monitoring job for {service_type} in deployment {deployment_id} is already running")
        return jsonify(message="Monitoring job is already running"), 409

    # Set the monitoring status in Redis
    state_redis_client.set(job_id, 'active')

    # Schedule the monitoring job
    scheduler.add_job(
        check_service, 'interval', seconds=5, id=job_id,
        args=[service_type, service_host, service_port, sidecar_url, job_id]
    )

    print(f"Started monitoring {service_type} for deployment {deployment_id}")
    return jsonify(message="Monitoring started"), 200

@app.route('/stop-monitoring', methods=['POST'])
def stop_monitoring():
    payload = request.get_json()
    service_type = payload['service_type']
    deployment_id = payload['deployment_id']
    job_id = f'{deployment_id}_{service_type}_monitor'

    # Set the monitoring status to inactive
    state_redis_client.set(job_id, 'inactive')
    scheduler.remove_job(job_id)
    print(f"Stopped monitoring {service_type} for deployment {deployment_id}")
    return jsonify(message="Monitoring stopped"), 200

if __name__ == "__main__":
    scheduler.start()
    app.run(host='0.0.0.0', port=5000)

----------------///---------
import requests
import time

def restart_and_check_health(hostname: str, port: int, retry_interval: int = 5, max_retries: int = 12):
    try:
        # Construct the URLs for the restart and health endpoints
        restart_url = f"http://{hostname}:{port}/restart"
        health_url = f"http://{hostname}:{port}/health"
        
        # Send a request to the /restart endpoint
        restart_response = requests.post(restart_url)
        restart_response.raise_for_status()
        print("Restart initiated successfully.")
        
        # Wait for 15 seconds before starting health checks
        print("Waiting for 15 seconds before checking health status...")
        time.sleep(15)
        
        # Check the /health endpoint periodically
        retries = 0
        while retries < max_retries:
            try:
                health_response = requests.get(health_url)
                if health_response.status_code == 200:
                    print("Pod is healthy.")
                    return True
            except requests.exceptions.RequestException as e:
                print(f"Health check attempt {retries + 1} failed: {e}")
            
            # Wait before retrying
            time.sleep(retry_interval)
            retries += 1
        
        print("Pod did not become healthy within the expected time.")
        return False
    except requests.exceptions.RequestException as e:
        print(f"An error occurred during restart: {e}")
        return False
_________________________________

from flask import Flask, request
import socket
import requests
import time

app = Flask(__name__)

@app.route('/broadcast', methods=['POST'])
def broadcast():
    service_name = "redismonitor-headless.cp-1049543.svc.cluster.local"
    port = 8080
    endpoint = "/reached"
    health_endpoint = "/health"
    
    initial_pod_ips = get_pod_ips(service_name)
    data = request.get_json()
    results = []
    
    for ip in initial_pod_ips:
        url = f"http://{ip}:{port}{endpoint}"
        print(url)
        response = requests.post(url, json=data)
        results.append(f"Response from {ip}: {response.status_code}")
        
        # Wait for 20 seconds before fetching the updated pod IP list
        time.sleep(20)
        
        # After hitting the /reached endpoint, get the updated list of pod IPs
        new_pod_ips = get_pod_ips(service_name)
        new_ip = list(set(new_pod_ips) - set(initial_pod_ips))
        
        # If a new IP is found, check if the new pod is up
        if new_ip:
            new_ip = new_ip[0]  # Assuming only one new IP will be there
            health_url = f"http://{new_ip}:{port}{health_endpoint}"
            health_response = requests.get(health_url)
            if health_response.status_code == 200:
                print(f"Pod at {new_ip} is up and running.")
        
        # Update the initial pod IPs list
        initial_pod_ips = new_pod_ips

    return "Broadcast complete. Results: " + ", ".join(results), 200

def get_pod_ips(service_name):
    try:
        pod_ips = socket.gethostbyname_ex(service_name)[2]
    except socket.gaierror as e:
        print(f"Error retrieving pod IPs: {e}")
        pod_ips = []
    return pod_ips

if __name__ == "__main__":
    app.run(host='0.0.0.0', port=8080)

--------------------------------------

import socket
import requests
from flask import Flask, request, jsonify
import time

app = Flask(__name__)

# Function to broadcast data to all pods
def broadcast_to_pods(service_name, port, endpoint, data):
    pod_ips = socket.gethostbyname_ex(service_name)[2]
    results = []

    for i, ip in enumerate(pod_ips):
        url = f"http://{ip}:{port}{endpoint}"
        print(url)
        
        # Check health of the first sidecar container
        if i == 0:
            health_url = f"http://{ip}:{port}/health"
            for _ in range(3):  # Try 3 times
                time.sleep(5)  # Wait for 5 seconds
                health_response = requests.get(health_url)
                if health_response.status_code == 200:
                    break
            else:
                return f"First sidecar container did not become healthy. Aborting restart.", 500
        
        response = requests.post(url, json=data)
        results.append(f"Response from {ip}: {response.status_code}")
    
    return results

@app.route('/broadcast', methods=['POST'])
def broadcast():
    service_name = "redismonitor-headless.cp-1049543.svc.cluster.local"
    port = 8080
    endpoint = "/reached"
    data = request.get_json()
    
    results = broadcast_to_pods(service_name, port, endpoint, data)
    return jsonify(message="Broadcast complete. Results: " + ", ".join(results)), 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)


--------------------------------------/////////////////////------------------------------

import socket
import requests
from flask import Flask, request, jsonify
import time

app = Flask(__name__)

# Function to broadcast data to all pods
def broadcast_to_pods(service_name, port, endpoint, data):
    try:
        pod_ips = socket.gethostbyname_ex(service_name)[2]
    except socket.gaierror as e:
        return f"Failed to resolve service name: {service_name}. Error: {e}", 500

    results = []

    for i, ip in enumerate(pod_ips):
        url = f"http://{ip}:{port}{endpoint}"
        print(url)
        
        try:
            response = requests.post(url, json=data)
            response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)
            results.append(f"Response from {ip}: {response.status_code}")
        except requests.RequestException as e:
            results.append(f"Failed to reach {ip}: {e}")
            continue
        
        # After restarting the first sidecar container, check its health
        if i == 0:
            health_url = f"http://{ip}:{port}/health"
            for attempt in range(3):  # Try 3 times
                time.sleep(5)  # Wait for 5 seconds
                try:
                    health_response = requests.get(health_url)
                    if health_response.status_code == 200:
                        break
                except requests.RequestException as e:
                    print(f"Attempt {attempt + 1} - Failed to reach {health_url}. Error: {e}")
            else:
                return f"First sidecar container did not become healthy. Aborting restart.", 500

    return results

@app.route('/broadcast', methods=['POST'])
def broadcast():
    service_name = "redismonitor-headless.cp-1049543.svc.cluster.local"
    port = 8080
    endpoint = "/reached"
    data = request.get_json()
    
    results = broadcast_to_pods(service_name, port, endpoint, data)
    
    if isinstance(results, tuple) and results[1] == 500:
        return jsonify(message=results[0]), 500
    
    return jsonify(message="Broadcast complete. Results: " + ", ".join(results)), 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
----------------------------------------------------------------

import socket
import requests
from flask import Flask, request, jsonify
import time

app = Flask(__name__)

# Function to broadcast data to all pods
def broadcast_to_pods(service_name, port, endpoint, data):
    try:
        pod_ips = socket.gethostbyname_ex(service_name)[2]
    except socket.gaierror as e:
        return f"Failed to resolve service name: {service_name}. Error: {e}", 500

    results = []

    for i, ip in enumerate(pod_ips):
        print(f"Starting iteration {i} for IP: {ip}")
        url = f"http://{ip}:{port}{endpoint}"
        print(f"URL: {url}")

        try:
            response = requests.post(url, json=data)
            response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)
            results.append(f"Response from {ip}: {response.status_code}")
        except requests.RequestException as e:
            print(f"Failed to reach {ip}. Error: {e}")
            results.append(f"Failed to reach {ip}: {e}")
            continue

        # After restarting the first sidecar container, check its health
        if i == 0:
            health_url = f"http://{ip}:{port}/health"
            print(f"Checking health at {health_url}")
            health_check_passed = False
            for attempt in range(3):  # Try 3 times
                time.sleep(5)  # Wait for 5 seconds
                try:
                    health_response = requests.get(health_url)
                    if health_response.status_code == 200:
                        health_check_passed = True
                        print(f"Health check passed on attempt {attempt + 1}")
                        break
                    else:
                        print(f"Health check failed with status code: {health_response.status_code}")
                except requests.RequestException as e:
                    print(f"Attempt {attempt + 1} - Failed to reach {health_url}. Error: {e}")
            
            if not health_check_passed:
                print("First sidecar container did not become healthy. Aborting restart.")
                return f"First sidecar container did not become healthy. Aborting restart.", 500

        print(f"Finished iteration {i} for IP: {ip}")

    return results

@app.route('/broadcast', methods=['POST'])
def broadcast():
    service_name = "redismonitor-headless.cp-1049543.svc.cluster.local"
    port = 8080
    endpoint = "/reached"
    data = request.get_json()
    
    results = broadcast_to_pods(service_name, port, endpoint, data)
    
    if isinstance(results, tuple) and results[1] == 500:
        return jsonify(message=results[0]), 500
    
    return jsonify(message="Broadcast complete. Results: " + ", ".join(results)), 200

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
---------------------------------------//////////////////=====================

def broadcast_to_pods(sidecar_url, port):
    pod_ips = get_pod_ips(sidecar_url)
    endpoint = "/restart"
    results = []

    for i, ip in enumerate(pod_ips):
        print(f"Starting iteration {i} for IP: {ip}")
        url = f"http://{ip}:{port}{endpoint}"
        print(f"URL: {url}")

        try:
            response = requests.get(url)
            response.raise_for_status()
            results.append(f"Response from {ip}: {response.status_code}")
        except requests.RequestException as e:
            print(f"Failed to reach {ip}. Error: {e}")
            results.append(f"Failed to reach {ip}. Error: {e}")
            continue

        # After restarting the first sidecar container, check its health
        if i == 0:
            health_url = f"http://{ip}:{port}/health"
            print(f"Checking health at {health_url}")
            health_check_passed = False
            for attempt in range(5):
                time.sleep(5)
                try:
                    health_response = requests.get(health_url)
                    if health_response.status_code == 200:
                        health_check_passed = True
                        print(f"Health check passed on attempt {attempt + 1}")
                        break
                    else:
                        print(f"Health check failed with status code: {health_response.status_code}")
                except requests.RequestException as e:
                    print(f"Attempt {attempt + 1} Failed to reach {health_url}. Error: {e}")

            if not health_check_passed:
                print("First sidecar container did not become healthy. Aborting restart.")
                return "First sidecar container did not become healthy. Aborting restart.", 500

        print(f"Finished iteration {i} for IP: {ip}")
        print(f"End of iteration {i}")  # Added debug statement

    print("Loop finished")  # Added debug statement
    return results




spec:
  containers:
    - name: <container-name>
      env:
        - name: JAVA_OPTS
          value: "-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp"





////////--------------/////

Based on the performance testing results that you've documented in Confluence, you can capture observations and recommendations for pod resources (memory and CPU) using the following insights:

### Observations:
1. **Scenario 1 (1 Pod) - 2400 & 4800 requests in 10 minutes:**
   - **CPU Usage:** 
     - At 2400 requests, the maximum CPU usage observed was 151m, with a throughput of 4 messages/second.
     - At 4800 requests, the CPU usage increased to 273m, with throughput doubling to 8 messages/second.
     - CPU usage still remained well below the 500m limit, indicating headroom for higher traffic.
   - **Memory Usage:** 
     - Memory consumption rose from 369Mi at 2400 requests to 565Mi at 4800 requests. 
     - Both memory usage patterns remain well under the 4Gi limit, indicating there is sufficient memory allocation even under higher traffic.

2. **Scenario 2 (3 Pods) - 2400 & 4800 requests in 10 minutes:**
   - **CPU Usage:** 
     - At 2400 requests, the CPU usage varied across the three pods (Pod1: 79m, Pod2: 66m, Pod3: 110m), averaging much lower than the single pod scenario.
     - At 4800 requests, the highest CPU usage was 153m (Pod1) and the average across the pods still remained below 500m per pod, maintaining good load distribution.
   - **Memory Usage:** 
     - Similar to CPU, memory consumption also varied across the pods (Pod1: 350Mi, Pod2: 310Mi, Pod3: 335Mi for 2400 requests).
     - At 4800 requests, memory usage increased slightly but still stayed well within the limits, ensuring good scalability across multiple replicas.

### Recommendations:
1. **CPU Recommendations:**
   - The observed CPU usage in both scenarios was consistently lower than the 500m CPU limit, which suggests that the limit can be further optimized. You might consider lowering the CPU request and limit for both single and multiple pod configurations.
   - **Suggested CPU Configurations:**
     - For 1 Pod: Request 150m, Limit 300m (since even at peak load, CPU usage remained well under 300m).
     - For 3 Pods: Request 100m, Limit 200m per pod (load distribution allows for lower limits).

2. **Memory Recommendations:**
   - Memory usage remained well below the 4Gi limit, even under the highest load conditions. This suggests potential over-allocation of memory resources.
   - **Suggested Memory Configurations:**
     - For 1 Pod: Request 1Gi, Limit 2Gi (since peak usage was below 600Mi, a 2Gi limit should suffice).
     - For 3 Pods: Request 750Mi, Limit 1.5Gi per pod (scalability ensures distributed memory consumption).

These recommendations should help optimize resource utilization while maintaining system performance under high traffic loads.

-------------
Here’s how you can revise the recommendations:

### Recommendations:
1. **CPU Recommendations:**
   - The CPU configurations are performing well within the allocated limits under all traffic scenarios. The observed usage consistently remains below the defined limits, indicating that the current CPU requests and limits are adequate.
   - **Conclusion:** No changes are required for CPU configurations.

2. **Memory Recommendations:**
   - Memory usage, while staying within limits, suggests potential over-allocation, especially since it doesn't approach the 4Gi limit, even under higher loads.
   - **Suggested Memory Configurations:**
     - For 1 Pod: Request 1Gi, Limit 2Gi (peak memory usage was below 600Mi).
     - For 3 Pods: Request 750Mi, Limit 1.5Gi per pod (ensuring good distribution across pods).

These memory adjustments should optimize resource utilization without compromising performance.



