apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: cubes-http-request-alert
  namespace: your-namespace
spec:
  groups:
    - name: cubes-http-alerts
      rules:
        - alert: HighHttpRequestRate
          expr: rate(http_server_requests_seconds_count{app="cubes"}[1m]) > 50
          for: 1m
          labels:
            severity: warning
            alertname: HighHttpRequestRate
          annotations:
            summary: "High HTTP request rate for cubes"
            description: "The cubes app is receiving more than 50 requests per minute in pod {{ $labels.pod }}."

count(
  kube_pod_status_phase{phase="Running", namespace="cp-1049543"}
  * on(pod) group_left()
  kube_pod_info{pod=~"kubes-data-connect-mongodb.*"}
)

- alert: NoRunningPodsForKubesDataConnectMongoDB
  expr: absent(kube_pod_status_phase{phase="Running", namespace="cp-1049543", pod=~"kubes-data-connect-mongodb.*"})
  for: 1m
  labels:
    severity: critical
  annotations:
    summary: "No running pods for kubes-data-connect-mongodb"
    description: "No running pods detected for kubes-data-connect-mongodb in namespace cp-1049543."

count(kube_pod_status_phase{phase="Running", namespace="cp-1049543", pod=~"kubes-data-connect-mongodb.*"}) == 0

count(
  kube_pod_status_phase{
    phase="Running",
    namespace="cp-1049543"
  }
  and on(pod)
  kube_pod_info{
    pod=~"kubes-data-connect-mongodb.*",
    pod!~".*-build$|.*-deploy$"
  }
) == 0

-------------------------------------------------------------------------------------------------

Here is a **Runbook / Standard Operating Procedure (SOP)** to deploy the **Sourcegraph application** in an **OpenShift environment**, based on the image you've provided:

---

# 📘 Runbook: Deploying Sourcegraph on OpenShift

## 🔰 Prerequisites

1. **Access Requirements**:

   * SSH access to the **jump server** (bastion host) with `helm` and `oc` CLI installed.
   * Access to **OpenShift cluster** via the `oc` CLI.
   * Access to **Bitbucket** (or other VCS) to clone the Sourcegraph codebase.

2. **Tools Required**:

   * `helm` (version compatible with chart, ideally Helm 3+)
   * `oc` CLI
   * `git`
   * OpenShift account with permissions to create/edit/delete resources.

---

Here's the **revised and detailed runbook** for deploying **Sourcegraph on OpenShift**, combining the information from the latest image and all previous instructions. This runbook is designed to be used as a **standard operating procedure (SOP)** for Dev, QA, and Prod environments.

---

# 📘 Sourcegraph Deployment Runbook for OpenShift

---

## 📌 Prerequisites

Before beginning the deployment, ensure the following:

1. **Jump Server Configuration**:

   * Access to a jump server (or CI runner) with:

     * `helm` installed (v3+)
     * `oc` CLI installed (OpenShift CLI)
   * Permissions to access the appropriate OpenShift cluster.

2. **Vendor Image Handling**:

   * The required Sourcegraph Docker images must be:

     * **Quarantined** and hosted in the **internal Artifactory repository**.
     * Used in place of the public Sourcegraph images.

3. **Bitbucket Repository Setup**:

   * Clone or maintain a Bitbucket repo structure like:

     ```
     sourcegraph-deploy/
     ├── charts/sourcegraph/
     ├── environments/
     │   ├── dev/
     │   │   └── override.yaml
     │   ├── qa/
     │   │   └── override.yaml
     │   └── prod/
     │       └── override.yaml
     └── deploy_sourcegraph.yml  # Ansible playbook
     ```

---

## 🧾 Step-by-Step Instructions

---

### 🛠️ Step 1: Quarantine Sourcegraph Images

* Identify the required version of Sourcegraph images.
* Mirror (quarantine) these images into your **organization’s internal Artifactory**.
* Ensure all image references in the `override.yaml` files point to Artifactory.

📘 *This is often handled by a platform/DevOps team and must follow internal vendor image security policy.*

---

### 🌿 Step 2: Prepare Bitbucket Repository

* Create a new feature or release branch in Bitbucket (e.g., `release/sourcegraph-v6.2.2553`).
* From GitHub Sourcegraph repo (`sourcegraph/deploy-sourcegraph-helm`), download the required chart version.
* **Exclude old/unused files** from your local repo except for `environments/lab` if it's in use.
* Extract the downloaded chart files into your local Bitbucket repo structure.
* Replace any existing files (except `override.yaml`) with the new files.

---

### 🖥️ Step 3: Pull Code to Jump Server (or CI)

* SSH into your **jump server** or Jenkins agent where deployment will happen.
* Use `git clone` or `git pull` to bring in the latest Sourcegraph Bitbucket branch.
* Confirm the following paths exist and are updated:

  * `charts/sourcegraph/`
  * `environments/<env>/override.yaml`

---

### 🧪 Step 4: Helm Template Rendering (Local Manifest Generation)

Use `helm template` to render Kubernetes manifests from the chart:

```bash
helm template sourcegraph ./charts/sourcegraph \
  --namespace <target-namespace> \
  --values ./environments/<env>/override.yaml \
  > ./environments/<env>/rendered.yaml
```

Replace `<env>` with `dev`, `qa`, or `prod`, and `<target-namespace>` accordingly.

---

### 🚮 Step 5: (Optional) Clean Existing Sourcegraph Resources

If this is a **re-deployment**, clean up existing Sourcegraph resources:

```bash
oc project <target-namespace>
oc delete deployments --all || true
oc delete statefulsets --all || true
oc delete replicasets --all || true
oc delete pods --all || true
```

---

### 🚀 Step 6: Apply the Rendered Manifests

```bash
oc apply -f ./environments/<env>/rendered.yaml
```

This will deploy Sourcegraph with your custom configuration to the selected OpenShift project.

---

### ✅ Step 7: Validate the Deployment

```bash
oc get all -n <target-namespace>
oc get routes -n <target-namespace>
```

* Hit the exposed route URL (from `oc get route`) in the browser.
* Confirm that the **Sourcegraph UI loads successfully**.

---

## 🧩 Optional: Automate with Ansible

If using Jenkins to trigger Ansible, use this \[Ansible Playbook structure]\(already provided above), and configure your Jenkinsfile to:

* Pull the repo.
* Pass environment as JSON to Ansible using `--extra-vars`.

---

## 🧾 Final Note

* Always maintain a backup of the existing `override.yaml` before making changes.
* Confirm Artifactory images are accessible from the OpenShift cluster.

---

Would you like this runbook exported as a markdown or Confluence-compatible format?



h2. 📌 Prerequisites

* Ensure the following are available on the jump server:
** {color:#172b4d}Helm v3 and oc CLI installed and configured{color}
** {color:#172b4d}Network access to external PostgreSQL DB{color}
** {color:#172b4d}Artifactory access to pull quarantined images{color}
* Vendor images must be quarantined in your organization’s Artifactory before deployment.
* Jenkins will pass a JSON with env-specific values and trigger the Ansible playbook.

---

h2. 🛠️ Step 1: Quarantine the Required Images

* Quarantine the required version of the Sourcegraph image in Artifactory.
* Tag and push them using:
{code:bash}
docker pull sourcegraph/sourcegraph:<tag>
docker tag sourcegraph/sourcegraph:<tag> artifactory.myorg.com/sourcegraph:<tag>
docker push artifactory.myorg.com/sourcegraph:<tag>
{code}

---

h2. 🌿 Step 2: Prepare Bitbucket Repository

* Create a new feature branch in Bitbucket.
* Clone the repo:
{code:bash}
git clone https://bitbucket.myorg.com/scm/team/deploy-sourcegraph-helm.git
cd deploy-sourcegraph-helm
git checkout -b feature/<env>-deployment
{code}

* Retain only the `environments/lab` folder locally.
* Replace older files with the latest extracted files for the target version from GitHub or Artifactory.

---

h2. 🖥️ Step 3: Pull Code to Jump Server

* You can do this either manually or through Jenkins.
* From VSCode or shell:
{code:bash}
git pull origin feature/<env>-deployment
{code}

---

h2. 🧪 Step 4: Helm Template Rendering

* Render manifests from your override files:
{code:bash}
helm template sourcegraph ./charts/sourcegraph \
  --namespace <target-namespace> \
  --values environments/<env>/values.yaml > environments/<env>/rendered.yaml
{code}

---

h2. 💾 Step 5: Backup PostgreSQL Database (External)

Before deleting any Sourcegraph resources, take a full backup of the PostgreSQL DB:

{code:bash}
PG_HOST=<postgres_host>
PG_PORT=5432
PG_USER=<postgres_user>
PG_DB=<sourcegraph_db>
BACKUP_DIR=/opt/db_backups/sourcegraph
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

PGPASSWORD=<postgres_password> pg_dump -h $PG_HOST -p $PG_PORT -U $PG_USER \
  -d $PG_DB -F c -f "$BACKUP_DIR/sourcegraph_backup_$TIMESTAMP.dump"
{code}

* Ensure credentials are securely managed and the backup is validated before proceeding.

---

h2. 🚮 Step 6: Delete Existing Sourcegraph Resources (Optional)

Switch to the correct project and delete old resources:
{code:bash}
oc project <target-namespace>
oc delete deployments,statefulsets,replicasets,pods --all
{code}

---

h2. 🚀 Step 7: Apply Helm-Rendered Manifests

{code:bash}
oc apply -f environments/<env>/rendered.yaml
{code}

---

h2. ✅ Step 8: Post-Deployment Validation

* Check pods and services:
{code:bash}
oc get all -n <target-namespace>
{code}

* Validate Sourcegraph route:
{code:bash}
oc get routes -n <target-namespace>
{code}

---

h2. 🔁 Optional: Jenkins + Ansible Workflow

* Jenkinsfile triggers Ansible and passes `env_vars.json`
* Ansible:
** Clones the repo
** Backs up PostgreSQL
** Deletes old resources
** Applies new manifests


💾 Step 5: Backup PostgreSQL Database
Before deleting any Sourcegraph resources, take a full backup of the Sourcegraph PostgreSQL database running on the external server.

Example Backup Script:
bash
Copy
Edit
# Replace the values below with actual ones
PG_HOST=<postgres_host>
PG_PORT=5432
PG_USER=<postgres_user>
PG_DB=<sourcegraph_db>
BACKUP_DIR=/opt/db_backups/sourcegraph
TIMESTAMP=$(date +%Y%m%d_%H%M%S)

mkdir -p $BACKUP_DIR

PGPASSWORD=<postgres_password> pg_dump -h $PG_HOST -p $PG_PORT -U $PG_USER -d $PG_DB -F c -f "$BACKUP_DIR/sourcegraph_backup_$TIMESTAMP.dump"

if [ $? -eq 0 ]; then
  echo "✅ PostgreSQL backup completed: $BACKUP_DIR/sourcegraph_backup_$TIMESTAMP.dump"
else
  echo "❌ PostgreSQL backup failed"
  exit 1
fi
✅ Ensure:

You have passwordless SSH or securely managed secrets.

The backup is automated and validated before proceeding.
