import asyncio
import aiohttp
from typing import Dict, Optional, Union, List
from fastapi import HTTPException
import logging

logger = logging.getLogger(__name__)

async def fetch_manifest(session, registry_url, image_name, tag, registry_token):
    manifest_api_url = f"https://{registry_url}/v2/{image_name}/manifests/{tag}"
    headers = {
        "Accept": "application/vnd.docker.distribution.manifest.v2+json",
        "Authorization": f"Bearer {registry_token}"
    }
    async with session.get(manifest_api_url, headers=headers, ssl=False) as resp:
        if resp.status != 200:
            logger.warning(f"Failed to fetch manifest for tag: {tag}")
            return tag, None
        return tag, await resp.json()

async def get_image_creation_date(registry_url, image_name, tag, registry_token):
    # Dummy placeholder for actual implementation
    # Replace this with your own `get_image_creation_date` logic
    return "2024-04-01T00:00:00Z"

async def get_image_digests_with_creation_dates_parallel(
    registry_url: str,
    image_name: str,
    registry_token: str,
    keep_tags: Union[List[str], None],
    tag_name: Optional[str] = None
) -> Dict:

    async with aiohttp.ClientSession() as session:
        # Step 1: Get all tags
        tags_url = f"https://{registry_url}/v2/{image_name}/tags/list"
        headers = {
            "Authorization": f"Bearer {registry_token}"
        }
        async with session.get(tags_url, headers=headers, ssl=False) as resp:
            if resp.status != 200:
                raise HTTPException(status_code=404, detail="Image tags not found")
            tags_list = (await resp.json()).get("tags", [])

        # Step 2: Validate input tags
        if tag_name:
            if "," in tag_name:
                split_tags = tag_name.split(",")
                for tag in split_tags:
                    if tag not in tags_list:
                        raise HTTPException(status_code=404, detail=f"Image with tag {image_name}:{tag} not found.")
            elif tag_name not in tags_list:
                raise HTTPException(status_code=404, detail=f"Image with tag {image_name}:{tag_name} not found.")

        # Step 3: Normalize keep_tags
        if isinstance(keep_tags, list):
            new_keep_tags = []
            for item in keep_tags:
                if isinstance(item, str) and "," in item:
                    new_keep_tags.extend(item.split(","))
                else:
                    new_keep_tags.extend([item])
            keep_tags = new_keep_tags
        else:
            logger.info(f"keep_tags is not a list: {keep_tags}")
            keep_tags = []

        # Step 4: Process tags with logic & parallel fetch
        async def process_tag(tag):
            if tag_name:
                if "," in tag_name:
                    if tag not in tag_name.split(","):
                        return None
                elif tag != tag_name:
                    return None

            if tag in keep_tags:
                logger.info(f"Skipping tag {tag} as it is in the skip list. tag: {tag}, skip_tags: {keep_tags}")
                return None

            tag, manifest = await fetch_manifest(session, registry_url, image_name, tag, registry_token)
            if not manifest:
                return None

            if "config" in manifest and "digest" in manifest["config"]:
                image_identifier = manifest["config"]["digest"]
                creation_date = await get_image_creation_date(registry_url, image_name, tag, registry_token)
                if creation_date:
                    return tag, {
                        "image_identifier": image_identifier,
                        "creation_date": creation_date
                    }
                else:
                    logger.warning(f"Failed to retrieve creation date for image: {image_name}:{tag}")
            else:
                logger.warning(f"Image config or digest not found in manifest for {image_name}:{tag}")
            return None

        results = await asyncio.gather(*(process_tag(tag) for tag in tags_list))
        tags_with_data = {tag: data for tag, data in results if tag and data}

        if not tags_with_data:
            logger.warning(f"No images found for {image_name} with tag {tag_name}.")
            return {}

        return tags_with_data
--------------------------------
  image_data = await get_image_digests_with_creation_dates_parallel(
        registry_url, image_name, registry_token, keep_tags, tag_name
    )

---------------------------*******Openshift process optimization****--************This is working****-----------


    if stale_images:
        try:
            v1_pods, v1_deployments, projects = get_kubesconfig(k8s_client)
        except Exception as e:
            logger.error(f"Failed to get OpenShift configurations: {e}")
            return {"message": "Failed to retrieve OpenShift configurations"}

        try:
            target_namespaces = get_target_namespaces(k8s_client, projects, filter_namespace)
        except Exception as e:
            logger.error(f"Failed to determine target namespaces: {e}")
            return {"message": "Failed to filter target namespaces"}

        for namespace in target_namespaces:
            try:
                deployments, pods = process_namespace(
                    k8s_client, v1_deployments, v1_pods, namespace, all_stale_images
                )
                matched_deployments.extend(deployments)
                matched_pods.extend(pods)
            except Exception as e:
                logger.error(f"Unexpected error processing namespace {namespace}: {e}")

    return {
        "stale_images": stale_images,
        "matched_deployments": matched_deployments,
        "matched_pods": matched_pods
    }

def get_target_namespaces(k8s_client, projects, filter_namespace: Optional[str]) -> List[str]:
    if filter_namespace:
        provided_namespaces = [ns.strip() for ns in filter_namespace.split(",")]
        logger.info(f"User provided namespaces: {provided_namespaces}")
        return [
            ns for ns in provided_namespaces
            if is_non_prod_namespace(k8s_client, ns)
        ]
    else:
        all_ns = []
        for project in projects:
            ns = project.metadata.name
            if is_non_prod_namespace(k8s_client, ns):
                all_ns.append(ns)
        logger.info(f"Discovered non-prod namespaces: {all_ns}")
        return all_ns


def match_stale_images_in_deployments(v1_deployments, namespace: str, all_stale_images: List[str]) -> List[dict]:
    matches = []
    try:
        deployments = v1_deployments.get(namespace=namespace)
        if not deployments or not deployments.items:
            logger.info(f"No deployments found in namespace {namespace}")
            return matches
        for deployment in deployments.items:
            for container in deployment.spec.template.spec.containers:
                if container.image in all_stale_images:
                    match = {
                        "namespace": namespace,
                        "deployment_name": deployment.metadata.name,
                        "image": container.image
                    }
                    matches.append(match)
                    logger.info(f"Matched stale image in deployment: {match}")
    except Exception as e:
        logger.warning(f"Failed to get deployments in namespace {namespace}: {e}")
    return matches


def match_stale_images_in_pods(v1_pods, namespace: str, all_stale_images: List[str]) -> List[dict]:
    matches = []
    try:
        pods = v1_pods.get(namespace=namespace)
        for pod in pods.items:
            for container in pod.spec.containers:
                if container.image in all_stale_images:
                    match = {
                        "namespace": namespace,
                        "pod_name": pod.metadata.name,
                        "image": container.image
                    }
                    matches.append(match)
                    logger.info(f"Matched stale image in pod: {match}")
    except Exception as e:
        logger.warning(f"Failed to get pods in namespace {namespace}: {e}")
    return matches


def process_namespace(k8s_client, v1_deployments, v1_pods, namespace: str, all_stale_images: List[str]) -> Tuple[List[dict], List[dict]]:
    logger.info(f"Processing namespace: {namespace}")
    deployments = match_stale_images_in_deployments(v1_deployments, namespace, all_stale_images)
    pods = match_stale_images_in_pods(v1_pods, namespace, all_stale_images)
    return deployments, pods

------------###### apply parallel processing on it ####------------

    # Build list of namespaces to check
    filter_ns_list = [ns.strip() for ns in filter_namespace.split(",")] if filter_namespace else None
    loop = asyncio.get_running_loop()
    namespaces = await loop.run_in_executor(executor, get_namespace_list, projects, filter_ns_list, k8s_client)

    matched_deployments = []
    matched_pods = []

    for ns in namespaces:
        deployments = await loop.run_in_executor(executor, get_deployments_in_namespace, v1_deployments, ns)
        if deployments:
            for deployment in deployments.items:
                for container in deployment.spec.template.spec.containers:
                    if container.image in all_stale_images:
                        matched_deployments.append({
                            "namespace": ns,
                            "deployment_name": deployment.metadata.name,
                            "image": container.image
                        })

        pods = await loop.run_in_executor(executor, get_pods_in_namespace, v1_pods, ns)
        if pods:
            for pod in pods.items:
                for container in pod.spec.containers:
                    if container.image in all_stale_images:
                        matched_pods.append({
                            "namespace": ns,
                            "pod_name": pod.metadata.name,
                            "image": container.image
                        })

def get_namespace_list(projects, filter_namespaces: Optional[List[str]], k8s_client):
    namespaces = []
    for project in projects:
        ns = project.metadata.name
        if filter_namespaces and ns not in filter_namespaces:
            continue
        if is_non_prod_namespace(k8s_client, ns):
            namespaces.append(ns)
    return namespaces


def get_deployments_in_namespace(v1_deployments, namespace):
    try:
        return v1_deployments.get(namespace=namespace)
    except Exception as e:
        logger.error(f"Failed to get deployments in {namespace}: {e}")
        return None


def get_pods_in_namespace(v1_pods, namespace):
    try:
        return v1_pods.get(namespace=namespace)
    except Exception as e:
        logger.error(f"Failed to get pods in {namespace}: {e}")
        return None

